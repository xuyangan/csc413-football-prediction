{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = 'berrar_ratings/data_recent_and_val_*.csv'\n",
    "files = glob.glob(file_pattern)\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    # change the format of the Date column\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "    full_df = pd.concat([full_df, df])\n",
    "\n",
    "# drop the Sea, Lge, GD, WDL columns\n",
    "full_df = full_df.drop(columns=['Sea', 'Lge', 'GD', 'WDL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the teams to index\n",
    "teams = full_df['HT'].unique()\n",
    "teams.sort()\n",
    "\n",
    "# create a dictionary to map the team names to integers\n",
    "team_to_idx = {team: idx for idx, team in enumerate(teams)}\n",
    "idx_to_team = {idx: team for team, idx in team_to_idx.items()}\n",
    "\n",
    "# add the team index to the dataframe\n",
    "full_df['HT'] = full_df['HT'].map(team_to_idx)\n",
    "full_df['AT'] = full_df['AT'].map(team_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " # sort the dataframe by date\n",
    "full_df = full_df.sort_values(by='Date')\n",
    "\n",
    "split_date = \"14/04/2023\"\n",
    "split_date = datetime.datetime.strptime(split_date, \"%d/%m/%Y\")\n",
    "\n",
    "df_train = full_df[full_df['Date'] < split_date]\n",
    "df_val = full_df[full_df['Date'] >= split_date]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    HT    AT  HS  AS  HT_H_Off_Rating  HT_H_Def_Rating  \\\n",
      "2 2019-01-26    50   167   2   1              0.0              0.0   \n",
      "0 2019-01-26   261   627   2   3              0.0              0.0   \n",
      "1 2019-01-26   534   618   0   5              0.0              0.0   \n",
      "3 2019-01-26   749   258   2   1              0.0              0.0   \n",
      "7 2019-01-27  1049  1052   4   1              0.0              0.0   \n",
      "\n",
      "   HT_A_Off_Rating  HT_A_Def_Rating  AT_H_Off_Rating  AT_H_Def_Rating  \\\n",
      "2              0.0              0.0              0.0              0.0   \n",
      "0              0.0              0.0              0.0              0.0   \n",
      "1              0.0              0.0              0.0              0.0   \n",
      "3              0.0              0.0              0.0              0.0   \n",
      "7              0.0              0.0              0.0              0.0   \n",
      "\n",
      "   AT_A_Off_Rating  AT_A_Def_Rating     HT_EG     AT_EG  \n",
      "2              0.0              0.0  1.239521  1.145053  \n",
      "0              0.0              0.0  1.239521  1.145053  \n",
      "1              0.0              0.0  1.239521  1.145053  \n",
      "3              0.0              0.0  1.239521  1.145053  \n",
      "7              0.0              0.0  1.239521  1.145053  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6312885348943215\n"
     ]
    }
   ],
   "source": [
    "# convert the dataframe into pytorch tensors\n",
    "\n",
    "training_teams = th.tensor(df_train[['HT', 'AT']].values, dtype=th.int64)\n",
    "training_ratings = th.tensor(df_train[['HT_H_Off_Rating', \n",
    "                                        'HT_H_Def_Rating',\n",
    "                                        'HT_A_Off_Rating', \n",
    "                                        'HT_A_Def_Rating',\n",
    "                                        'AT_H_Off_Rating', \n",
    "                                        'AT_H_Def_Rating',\n",
    "                                        'AT_A_Off_Rating',\n",
    "                                        'AT_A_Def_Rating']].values, dtype=th.float32)\n",
    "\n",
    "training_data = th.cat([training_teams, training_ratings], dim=1)\n",
    "training_labels = th.tensor(df_train[['HS', 'AS']].values, dtype=th.float32)\n",
    "\n",
    "testing_teams = th.tensor(df_val[['HT', 'AT']].values, dtype=th.int64)\n",
    "testing_ratings = th.tensor(df_val[['HT_H_Off_Rating', \n",
    "                                    'HT_H_Def_Rating',\n",
    "                                    'HT_A_Off_Rating', \n",
    "                                    'HT_A_Def_Rating',\n",
    "                                    'AT_H_Off_Rating', \n",
    "                                    'AT_H_Def_Rating',\n",
    "                                    'AT_A_Off_Rating',\n",
    "                                    'AT_A_Def_Rating']].values, dtype=th.float32)\n",
    "testing_data = th.cat([testing_teams, testing_ratings], dim=1)\n",
    "testing_labels = th.tensor(df_val[['HS', 'AS']].values, dtype=th.float32)\n",
    "\n",
    "# separate the training set into training and validation sets\n",
    "split = int(0.8 * training_data.shape[0])\n",
    "train_data = training_data[:split]\n",
    "train_labels = training_labels[:split]\n",
    "val_data = training_data[split:]\n",
    "val_labels = training_labels[split:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6312885348943215\n"
     ]
    }
   ],
   "source": [
    "# training_expected_labels = th.tensor(df_train[['HT_EG', 'AT_EG']].values, dtype=th.float32)\n",
    "\n",
    "# total = 0\n",
    "# count = 0\n",
    "\n",
    "# for i in range(training_labels.shape[0]):\n",
    "#     home_score = training_labels[i][0]\n",
    "#     away_score = training_labels[i][1]\n",
    "#     home_expected_goals = training_expected_labels[i][0]\n",
    "#     away_expected_goals = training_expected_labels[i][1]\n",
    "#     if home_score > away_score:\n",
    "#         total += 1\n",
    "#         if home_expected_goals > away_expected_goals:\n",
    "#             count += 1\n",
    "#     elif home_score < away_score:\n",
    "#         total += 1\n",
    "#         if home_expected_goals < away_expected_goals:\n",
    "#             count += 1\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "# print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception block\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernel=4, init_weights=True):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernel = num_kernel\n",
    "        kernels = []\n",
    "        for i in range(1, num_kernel + 1):\n",
    "            # kernels.append(nn.Conv2d(in_channels, out_channels // num_kernel, kernel_size=i * 2 + 1, padding=i))\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=i * 2 + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i in range(self.num_kernel):\n",
    "            outputs.append(self.kernels[i](x))\n",
    "        # outputs = th.stack(outputs, dim=1)\n",
    "        outputs = th.cat(outputs, dim=1).mean(dim=1)\n",
    "\n",
    "        # do i want to add a relu here (??)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMBlock, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # do i want to ude the last layer only (??)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of the model\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class FootBallPredictionConfig:\n",
    "    num_teams: int\n",
    "    num_features: int\n",
    "    num_labels: int\n",
    "    num_inception_blocks: int\n",
    "    num_lstm_layers: int\n",
    "    hidden_size: int\n",
    "    output_size: int\n",
    "    num_epochs: int\n",
    "    learning_rate: float\n",
    "    batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needc an embedding layer for the teams before the feedforward network\n",
    "\n",
    "class FootballPrediction(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FootballPrediction, self).__init__()\n",
    "        self.team_embedding = nn.Embedding(num_teams, 10)\n",
    "        # inception block\n",
    "        self.inception_block = [InceptionBlock(num_features + 10, 64) for _ in range(num_inception_blocks)]\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        # would need a module that processes the sequential features\n",
    "        # self.feedforward = nn.Sequential(\n",
    "        #     nn.Linear(num_features + 10, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, num_labels)\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do we need to computer the berrar ratings here (??) or does the \n",
    "        # input already contain the berrar ratings (??)\n",
    "        \n",
    "        # replace the team indexes with the embeddings\n",
    "        home_team = self.team_embedding(x[:, 0].long())\n",
    "        away_team = self.team_embedding(x[:, 1].long())\n",
    "        x = th.cat([x[:, 2:], home_team, away_team], dim=1)\n",
    "\n",
    "        # pass through the inception block\n",
    "        for block in self.inception_block:\n",
    "            x = block(x)\n",
    "\n",
    "\n",
    "        \n",
    "        return self.feedforward(x)\n",
    "    \n",
    "\n",
    "    def predict(self, x):\n",
    "        # have to decide on what is the shape for the input\n",
    "\n",
    "        return self.forward(x)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import glob\n","import numpy as np"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[],"source":["features_to_keep = [    \n","                        \"HT\",\n","                        \"AT\",\n","                        \"HS\",\n","                        \"AS\",\n","                        \"HST\",\n","                        \"AST\",\n","                        \"HC\",\n","                        \"AC\",\n","                        \"HF\",\n","                        \"AF\",\n","                        \"HFKC\",\n","                        \"AFKC\",\n","                        \"HY\",\n","                        \"AY\",\n","                        \"HR\",\n","                        \"AR\",\n","                        \"B365H\",\n","                        \"B365D\",\n","                        \"B365A\",\n","                        'HT_H_Off_Rating', \n","                        'HT_H_Def_Rating',\n","                        'HT_A_Off_Rating', \n","                        'HT_A_Def_Rating',\n","                        'AT_H_Off_Rating', \n","                        'AT_H_Def_Rating',\n","                        'AT_A_Off_Rating',\n","                        'AT_A_Def_Rating'\n","]\n","\n","labels_to_keep = [  \n","                    \"HT\",\n","                    \"AT\",\n","                    \"FTR\",\n","                    \"FTHG\",\n","                    \"FTAG\"\n","]\n"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[],"source":["def load_berrar_ratings():\n","    file_pattern = '../berrar_ratings/full*.csv'\n","    files = glob.glob(file_pattern)\n","    full_df = pd.DataFrame()\n","    for file in files:\n","        df = pd.read_csv(file)\n","        df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n","        full_df = pd.concat([full_df, df])\n","    full_df = full_df.reset_index().set_index('Date')\n","    full_df = full_df.sort_values('Date')\n","    full_target = full_df[labels_to_keep]\n","    full_data = full_df[features_to_keep]\n","    return full_df, full_data, full_target"]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HT</th>\n","      <th>AT</th>\n","      <th>HS</th>\n","      <th>AS</th>\n","      <th>HST</th>\n","      <th>AST</th>\n","      <th>HC</th>\n","      <th>AC</th>\n","      <th>HF</th>\n","      <th>AF</th>\n","      <th>...</th>\n","      <th>B365D</th>\n","      <th>B365A</th>\n","      <th>HT_H_Off_Rating</th>\n","      <th>HT_H_Def_Rating</th>\n","      <th>HT_A_Off_Rating</th>\n","      <th>HT_A_Def_Rating</th>\n","      <th>AT_H_Off_Rating</th>\n","      <th>AT_H_Def_Rating</th>\n","      <th>AT_A_Off_Rating</th>\n","      <th>AT_A_Def_Rating</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2016-07-29</th>\n","      <td>Troyes</td>\n","      <td>Sochaux</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>3.00</td>\n","      <td>2.80</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2016-07-29</th>\n","      <td>Orleans</td>\n","      <td>Le Havre</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>2.90</td>\n","      <td>2.40</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2016-07-29</th>\n","      <td>Niort</td>\n","      <td>Lens</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>2.88</td>\n","      <td>2.90</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2016-07-29</th>\n","      <td>Nimes</td>\n","      <td>Laval</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>3.00</td>\n","      <td>3.60</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2016-07-29</th>\n","      <td>Bourg Peronnas</td>\n","      <td>Strasbourg</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>2.88</td>\n","      <td>2.90</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2024-04-16</th>\n","      <td>Portsmouth</td>\n","      <td>Barnsley</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>15.0</td>\n","      <td>10.0</td>\n","      <td>...</td>\n","      <td>3.80</td>\n","      <td>4.33</td>\n","      <td>8.308275</td>\n","      <td>1.232432</td>\n","      <td>3.776679</td>\n","      <td>-8.493096</td>\n","      <td>2.574335</td>\n","      <td>3.718900</td>\n","      <td>8.830549</td>\n","      <td>-4.140576</td>\n","    </tr>\n","    <tr>\n","      <th>2024-04-16</th>\n","      <td>Bristol Rvs</td>\n","      <td>Cambridge</td>\n","      <td>15.0</td>\n","      <td>12.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>8.0</td>\n","      <td>...</td>\n","      <td>3.50</td>\n","      <td>3.20</td>\n","      <td>-7.264987</td>\n","      <td>3.824095</td>\n","      <td>2.212059</td>\n","      <td>2.717884</td>\n","      <td>-7.787984</td>\n","      <td>0.672644</td>\n","      <td>-1.267636</td>\n","      <td>3.981673</td>\n","    </tr>\n","    <tr>\n","      <th>2024-04-16</th>\n","      <td>Bolton</td>\n","      <td>Shrewsbury</td>\n","      <td>25.0</td>\n","      <td>8.0</td>\n","      <td>13.0</td>\n","      <td>3.0</td>\n","      <td>12.0</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","      <td>9.0</td>\n","      <td>...</td>\n","      <td>5.50</td>\n","      <td>9.50</td>\n","      <td>12.924197</td>\n","      <td>-0.280759</td>\n","      <td>4.404778</td>\n","      <td>-4.811224</td>\n","      <td>-9.504516</td>\n","      <td>3.345889</td>\n","      <td>-2.320528</td>\n","      <td>-2.681133</td>\n","    </tr>\n","    <tr>\n","      <th>2024-04-16</th>\n","      <td>Peterboro</td>\n","      <td>Fleetwood Town</td>\n","      <td>14.0</td>\n","      <td>10.0</td>\n","      <td>7.0</td>\n","      <td>7.0</td>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>9.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>4.75</td>\n","      <td>5.50</td>\n","      <td>10.765210</td>\n","      <td>1.997933</td>\n","      <td>6.514204</td>\n","      <td>-1.665527</td>\n","      <td>-5.060588</td>\n","      <td>2.946941</td>\n","      <td>1.282105</td>\n","      <td>0.491536</td>\n","    </tr>\n","    <tr>\n","      <th>2024-04-16</th>\n","      <td>Oxford</td>\n","      <td>Lincoln</td>\n","      <td>17.0</td>\n","      <td>8.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>8.0</td>\n","      <td>3.0</td>\n","      <td>12.0</td>\n","      <td>16.0</td>\n","      <td>...</td>\n","      <td>3.60</td>\n","      <td>3.80</td>\n","      <td>10.621895</td>\n","      <td>1.141281</td>\n","      <td>4.259645</td>\n","      <td>-2.270290</td>\n","      <td>1.822878</td>\n","      <td>-3.446497</td>\n","      <td>4.397609</td>\n","      <td>-4.683301</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>30406 rows × 27 columns</p>\n","</div>"],"text/plain":["                        HT              AT    HS    AS   HST  AST    HC   AC  \\\n","Date                                                                           \n","2016-07-29          Troyes         Sochaux   0.0   0.0   0.0  0.0   0.0  0.0   \n","2016-07-29         Orleans        Le Havre   0.0   0.0   0.0  0.0   0.0  0.0   \n","2016-07-29           Niort            Lens   0.0   0.0   0.0  0.0   0.0  0.0   \n","2016-07-29           Nimes           Laval   0.0   0.0   0.0  0.0   0.0  0.0   \n","2016-07-29  Bourg Peronnas      Strasbourg   0.0   0.0   0.0  0.0   0.0  0.0   \n","...                    ...             ...   ...   ...   ...  ...   ...  ...   \n","2024-04-16      Portsmouth        Barnsley  14.0  14.0   4.0  5.0   3.0  3.0   \n","2024-04-16     Bristol Rvs       Cambridge  15.0  12.0   5.0  2.0   4.0  6.0   \n","2024-04-16          Bolton      Shrewsbury  25.0   8.0  13.0  3.0  12.0  5.0   \n","2024-04-16       Peterboro  Fleetwood Town  14.0  10.0   7.0  7.0   7.0  4.0   \n","2024-04-16          Oxford         Lincoln  17.0   8.0   5.0  3.0   8.0  3.0   \n","\n","              HF    AF  ...  B365D  B365A  HT_H_Off_Rating  HT_H_Def_Rating  \\\n","Date                    ...                                                   \n","2016-07-29   0.0   0.0  ...   3.00   2.80         0.000000         0.000000   \n","2016-07-29   0.0   0.0  ...   2.90   2.40         0.000000         0.000000   \n","2016-07-29   0.0   0.0  ...   2.88   2.90         0.000000         0.000000   \n","2016-07-29   0.0   0.0  ...   3.00   3.60         0.000000         0.000000   \n","2016-07-29   0.0   0.0  ...   2.88   2.90         0.000000         0.000000   \n","...          ...   ...  ...    ...    ...              ...              ...   \n","2024-04-16  15.0  10.0  ...   3.80   4.33         8.308275         1.232432   \n","2024-04-16   8.0   8.0  ...   3.50   3.20        -7.264987         3.824095   \n","2024-04-16   4.0   9.0  ...   5.50   9.50        12.924197        -0.280759   \n","2024-04-16   9.0   7.0  ...   4.75   5.50        10.765210         1.997933   \n","2024-04-16  12.0  16.0  ...   3.60   3.80        10.621895         1.141281   \n","\n","            HT_A_Off_Rating  HT_A_Def_Rating  AT_H_Off_Rating  \\\n","Date                                                            \n","2016-07-29         0.000000         0.000000         0.000000   \n","2016-07-29         0.000000         0.000000         0.000000   \n","2016-07-29         0.000000         0.000000         0.000000   \n","2016-07-29         0.000000         0.000000         0.000000   \n","2016-07-29         0.000000         0.000000         0.000000   \n","...                     ...              ...              ...   \n","2024-04-16         3.776679        -8.493096         2.574335   \n","2024-04-16         2.212059         2.717884        -7.787984   \n","2024-04-16         4.404778        -4.811224        -9.504516   \n","2024-04-16         6.514204        -1.665527        -5.060588   \n","2024-04-16         4.259645        -2.270290         1.822878   \n","\n","            AT_H_Def_Rating  AT_A_Off_Rating  AT_A_Def_Rating  \n","Date                                                           \n","2016-07-29         0.000000         0.000000         0.000000  \n","2016-07-29         0.000000         0.000000         0.000000  \n","2016-07-29         0.000000         0.000000         0.000000  \n","2016-07-29         0.000000         0.000000         0.000000  \n","2016-07-29         0.000000         0.000000         0.000000  \n","...                     ...              ...              ...  \n","2024-04-16         3.718900         8.830549        -4.140576  \n","2024-04-16         0.672644        -1.267636         3.981673  \n","2024-04-16         3.345889        -2.320528        -2.681133  \n","2024-04-16         2.946941         1.282105         0.491536  \n","2024-04-16        -3.446497         4.397609        -4.683301  \n","\n","[30406 rows x 27 columns]"]},"execution_count":177,"metadata":{},"output_type":"execute_result"}],"source":["full_df, full_data, full_target = load_berrar_ratings()\n","full_data"]},{"cell_type":"code","execution_count":178,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Berrar ratings accuracy for only A and H:  0.6548253137130993\n"]}],"source":["# test how well the berrar ratings do for predicting A vs H\n","def test_berrar_ratings(df):\n","    total = 0\n","    right_counts = 0\n","    # keep \"FTR\", \"HT_EG\", \"AT_EG\"\n","    small = df[[\"FTR\", \"HT_EG\", \"AT_EG\"]]\n","    # change to list of lists\n","    for row in small.values:\n","        pred_home_goals = row[1]\n","        pred_away_goals = row[2]\n","\n","        if pred_home_goals > pred_away_goals:\n","            pred = \"H\"\n","        elif pred_home_goals < pred_away_goals:\n","            pred = \"A\"\n","        if pred == row[0]:\n","            right_counts += 1\n","        if row[0] == \"H\" or row[0] == \"A\":\n","            total += 1\n","    print(\"Berrar ratings accuracy for only A and H: \", right_counts/total)\n","    return None\n","\n","test_berrar_ratings(full_df)"]},{"cell_type":"code","execution_count":179,"metadata":{},"outputs":[],"source":["home_team_features = [\n","                        'HT_H_Off_Rating',\n","                        'HT_H_Def_Rating',\n","                        'HT_A_Off_Rating',\n","                        'HT_A_Def_Rating',\n","                        \"HS\",\n","                        \"HST\",\n","                        \"HC\",\n","                        \"HF\",\n","                        \"HFKC\",\n","                        \"HY\",\n","                        \"HR\",\n","                        \"B365H\",\n","                        \"B365D\",\n","                        \"B365A\"\n","]   \n","\n","away_team_features = [  \n","                        'AT_H_Off_Rating',\n","                        'AT_H_Def_Rating',\n","                        'AT_A_Off_Rating',\n","                        'AT_A_Def_Rating',\n","                        \"AS\",\n","                        \"AST\",\n","                        \"AC\",\n","                        \"AF\",\n","                        \"AFKC\",\n","                        \"AY\",\n","                        \"AR\",\n","                        \"B365H\",\n","                        \"B365D\",\n","                        \"B365A\"\n","]\n"]},{"cell_type":"code","execution_count":180,"metadata":{},"outputs":[],"source":["def get_team_history_rating(df, label, team, n_stagger, before_date, features):\n","        before_df = df.reset_index().set_index([\"Date\"]).sort_index()\n","        # before_df = before_df.loc[:before_date]\n","        # get the games before the date or equal to the date\n","        before_df = before_df[before_df.index <= before_date]\n","        before_df = before_df[before_df[label] == team]\n","        # if there is less than n_stagger games before the date, \n","        eval = n_stagger - len(before_df)\n","        if eval > 0:\n","            return None \n","            # nan_rows = pd.DataFrame(np.nan, index=range(eval), columns=before_df.columns)\n","            # before_df = pd.concat([nan_rows, before_df])\n","            # before_df = before_df.fillna(0)\n","        \n","        else:\n","            before_df = before_df.iloc[-n_stagger:]\n","        before_df = before_df[features]\n","        return before_df\n","\n","        \n","# test\n","# get_team_history_rating(full_data, 'AT', 'Liverpool', 5, '2019-12-26', away_team_features)"]},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/bh/nzvgvn0x76b43w8p9n29j1bm0000gn/T/ipykernel_80933/1549758412.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  full_data[\"HT\"] = full_data[\"HT\"].map(teams_to_idx)\n","/var/folders/bh/nzvgvn0x76b43w8p9n29j1bm0000gn/T/ipykernel_80933/1549758412.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  full_data[\"AT\"] = full_data[\"AT\"].map(teams_to_idx)\n","/var/folders/bh/nzvgvn0x76b43w8p9n29j1bm0000gn/T/ipykernel_80933/1549758412.py:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  full_target[\"HT\"] = full_target[\"HT\"].map(teams_to_idx)\n","/var/folders/bh/nzvgvn0x76b43w8p9n29j1bm0000gn/T/ipykernel_80933/1549758412.py:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  full_target[\"AT\"] = full_target[\"AT\"].map(teams_to_idx)\n"]}],"source":["\n","result_map = {  \n","            \"H\": 0,\n","            \"D\": 1,\n","            \"A\": 2\n","}\n","\n","teams = full_df[\"HT\"].unique()\n","teams_to_idx = {team: idx for idx, team in enumerate(teams)}\n","idx_to_teams = {idx: team for idx, team in enumerate(teams)}\n","# change the team names to indexes\n","full_data[\"HT\"] = full_data[\"HT\"].map(teams_to_idx)\n","full_data[\"AT\"] = full_data[\"AT\"].map(teams_to_idx)\n","full_target[\"HT\"] = full_target[\"HT\"].map(teams_to_idx)\n","full_target[\"AT\"] = full_target[\"AT\"].map(teams_to_idx)\n"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[],"source":["import torch as th\n","\n","def compute_history(full_data, full_target, n_stagger):\n","\n","    data_dp = full_data.copy()\n","    target_dp = full_target.copy().reset_index()\n","    data_dp.reset_index().set_index([\"Date\", \"HT\", \"AT\"]).sort_index()\n","    target_dp.reset_index().set_index([\"Date\", \"HT\", \"AT\"]).sort_index()\n","\n","\n","    # shape num_matches x n_stagger x num_features\n","    matches_features_home = []\n","    matches_features_away = []\n","\n","    targets = []\n","\n","    # map the result to a number\n","    # target_dp = target_dp[\"FTR\"].map(result_map)\n","    # targets = th.tensor(target_dp.values, dtype=th.long)\n","\n","    home_teams_matches = []\n","    away_teams_matches = []\n","\n","    for index, row in data_dp.iterrows():\n","        # this is match\n","        date = index\n","        home_team = row[\"HT\"]\n","        away_team = row[\"AT\"]\n","\n","        # there are n_stagger rows with num_features columns\n","        home_history = get_team_history_rating(data_dp, 'HT', home_team, n_stagger, date, home_team_features)\n","        if home_history is None:\n","            continue\n","        # shape n_stagger x num_features\n","        away_history = get_team_history_rating(data_dp, 'AT', away_team, n_stagger, date, away_team_features)\n","        if away_history is None:\n","            continue\n","        \n","        # shape n_stagger x num_features\n","        feature_home = th.tensor(home_history.values, dtype=th.float)\n","        feature_away = th.tensor(away_history.values, dtype=th.float)\n","\n","        # append in another dimension\n","        matches_features_home.append(feature_home.unsqueeze(0))\n","        matches_features_away.append(feature_away.unsqueeze(0))\n","\n","        target = target_dp.loc[target_dp[\"Date\"] == date]\n","        target = target.loc[target[\"HT\"] == home_team]\n","        target = target.loc[target[\"AT\"] == away_team]\n","        target = target[\"FTR\"].values[0]\n","        targets.append(result_map[target])\n","\n","        home_teams_matches.append(home_team)\n","        away_teams_matches.append(away_team)\n","        \n","    matches_features_home = th.cat(matches_features_home, dim=0)\n","    matches_features_away = th.cat(matches_features_away, dim=0)\n","    targets = th.tensor(targets, dtype=th.long)\n","    home_teams_matches = th.tensor(home_teams_matches, dtype=th.long)\n","    away_teams_matches = th.tensor(away_teams_matches, dtype=th.long)\n","\n","    return home_teams_matches, away_teams_matches, matches_features_home, matches_features_away, targets\n","\n"]},{"cell_type":"code","execution_count":183,"metadata":{},"outputs":[],"source":["# separate into training and test set\n","\n","date = \"2023-04-14\"\n","\n","training_data_df = full_data.loc[:date]\n","training_target_df = full_target.loc[:date]\n","\n","test_data_df = full_data.loc[date:]\n","test_target_df = full_target.loc[date:]\n","\n","\n","training_home_teams_matches, training_away_teams_matches, \\\n","    training_matches_features_home, training_matches_features_away, \\\n","        training_targets = compute_history(training_data_df, training_target_df, 5)\n","\n","test_home_teams_matches, test_away_teams_matches, \\\n","    test_matches_features_home, test_matches_features_away, \\\n","        test_targets = compute_history(test_data_df, test_target_df, 5)\n","\n"]},{"cell_type":"code","execution_count":184,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([24843])\n","torch.Size([24843])\n","torch.Size([24843, 5, 14])\n","torch.Size([24843, 5, 14])\n","torch.Size([24843])\n","-------------------\n","torch.Size([3072])\n","torch.Size([3072])\n","torch.Size([3072, 5, 14])\n","torch.Size([3072, 5, 14])\n","torch.Size([3072])\n"]}],"source":["print(training_home_teams_matches.shape)\n","print(training_away_teams_matches.shape)\n","print(training_matches_features_away.shape)\n","print(training_matches_features_home.shape)\n","print(training_targets.shape)\n","print(\"-------------------\")\n","print(test_home_teams_matches.shape)\n","print(test_away_teams_matches.shape)\n","print(test_matches_features_home.shape)\n","print(test_matches_features_away.shape)\n","print(test_targets.shape)"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["import pickle\n","# save the tensors to disk\n","\n","folder = \"tensors\"\n","th.save(training_home_teams_matches, f'../{folder}/training_home_teams_matches.pt')\n","th.save(training_away_teams_matches, f'../{folder}/training_away_teams_matches.pt')\n","th.save(training_matches_features_home, f'../{folder}/training_matches_features_home.pt')\n","th.save(training_matches_features_away, f'../{folder}/training_matches_features_away.pt')\n","th.save(training_targets, f'../{folder}/training_targets.pt')\n","\n","th.save(test_home_teams_matches, f'../{folder}/test_home_teams_matches.pt')\n","th.save(test_away_teams_matches, f'../{folder}/test_away_teams_matches.pt')\n","th.save(test_matches_features_home, f'../{folder}/test_matches_features_home.pt')\n","th.save(test_matches_features_away, f'../{folder}/test_matches_features_away.pt')\n","th.save(test_targets, f'../{folder}/test_targets.pt')\n","\n","# save the dictionaries\n","\n","with open(f'../{folder}/result_map.pkl', 'wb') as f:\n","    pickle.dump(result_map, f)\n","\n","with open(f'../{folder}/teams_to_idx.pkl', 'wb') as f:\n","    pickle.dump(teams_to_idx, f)\n","\n","with open(f'../{folder}/idx_to_teams.pkl', 'wb') as f:\n","    pickle.dump(idx_to_teams, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}

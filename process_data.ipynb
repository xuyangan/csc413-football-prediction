{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49930 lines in 42 files\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "# read the data from the csv files\n",
    "file_pattern = 'berrar_rating/trainset_22-23_exact_44_*.csv'\n",
    "files = glob.glob(file_pattern)\n",
    "\n",
    "raw_data = []\n",
    "\n",
    "# dictionary to convert the WLD to an integer\n",
    "wld_to_idx = {'W': 0, 'D': 1, 'L': 2}\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # skip the header\n",
    "        next(reader)\n",
    "        for line in reader:\n",
    "            # conver to datetime object for line[3] that has format \"17/08/2019\"\n",
    "            date = datetime.datetime.strptime(line[3], '%d/%m/%Y')\n",
    "            home_team = line[4]\n",
    "            away_team = line[5]\n",
    "            # turn into integers/floats\n",
    "            home_score = int(line[6])\n",
    "            away_score = int(line[7])\n",
    "            goal_diff = int(line[8])\n",
    "            win_draw_loss = wld_to_idx[line[9]]\n",
    "            ht_home_offensive_rating = float(line[10])\n",
    "            ht_home_defensive_rating = float(line[11])\n",
    "            ht_away_offensive_rating = float(line[12])\n",
    "            ht_away_defensive_rating = float(line[13])\n",
    "            at_home_offensive_rating = float(line[14])\n",
    "            at_home_defensive_rating = float(line[15])\n",
    "            at_away_offensive_rating = float(line[16])\n",
    "            at_away_defensive_rating = float(line[17])\n",
    "            ht_expected_goals = float(line[18])\n",
    "            at_expected_goals = float(line[19])\n",
    "            line_information = [date, \n",
    "                                home_team, \n",
    "                                away_team,\n",
    "                                home_score,\n",
    "                                away_score,\n",
    "                                goal_diff,\n",
    "                                win_draw_loss,\n",
    "                                ht_home_offensive_rating,\n",
    "                                ht_home_defensive_rating,\n",
    "                                ht_away_offensive_rating,\n",
    "                                ht_away_defensive_rating,\n",
    "                                at_home_offensive_rating,\n",
    "                                at_home_defensive_rating,\n",
    "                                at_away_offensive_rating,\n",
    "                                at_away_defensive_rating,\n",
    "                                ht_expected_goals,\n",
    "                                at_expected_goals]\n",
    "            raw_data.append(line_information)\n",
    "\n",
    "print(f'Found {len(raw_data)} lines in {len(files)} files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header has the following format\n",
    "# index,Sea,Lge,Date,HT,AT,HS,AS,GD,WDL,Round,HT_H_Off_Rating,HT_H_Def_Rating,HT_A_Off_Rating,HT_A_Def_Rating,AT_H_Off_Rating,AT_H_Def_Rating,AT_A_Off_Rating,AT_A_Def_Rating,HT_EG,AT_EG\n",
    "# where:\n",
    "\n",
    "# HT_H_Off_Rating - Home team home offensive rating\n",
    "# HT_H_Def_Rating - Home team home defensive rating\n",
    "# HT_A_Off_Rating - Home team away offensive rating\n",
    "# HT_A_Def_Rating - Home team away defensive rating\n",
    "# AT_H_Off_Rating - Away team home offensive rating\n",
    "# AT_H_Def_Rating - Away team home defensive rating\n",
    "# AT_A_Off_Rating - Away team away offensive rating\n",
    "# AT_A_Def_Rating - Away team away defensive rating\n",
    "# AT_EG - Away team expected goals\n",
    "# HT_EG - Home team expected goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of teams:  907\n",
      "Training data size:  34951\n",
      "Validation data size:  7489\n",
      "Test data size:  7490\n"
     ]
    }
   ],
   "source": [
    "# sort by date\n",
    "raw_data.sort(key=lambda x: x[0])\n",
    "\n",
    "# change the teams to indexes\n",
    "teams = set([x[1] for x in raw_data] + [x[2] for x in raw_data])\n",
    "team_to_idx = {team: idx for idx, team in enumerate(teams)}\n",
    "idx_to_team = {idx: team for team, idx in team_to_idx.items()}\n",
    "\n",
    "print (\"Number of teams: \", len(teams))\n",
    "\n",
    "features = th.zeros(len(raw_data), 10)\n",
    "labels = th.zeros(len(raw_data), 4)\n",
    "\n",
    "# change the teams to indeces\n",
    "for i in range(len(raw_data)):\n",
    "    # change the teams to indexes\n",
    "    home_team_idx = team_to_idx[raw_data[i][1]]\n",
    "    away_team_idx = team_to_idx[raw_data[i][2]]\n",
    "\n",
    "    features[i] = th.tensor([\n",
    "        home_team_idx, away_team_idx, raw_data[i][7],\n",
    "        raw_data[i][8], raw_data[i][9], raw_data[i][10],\n",
    "        raw_data[i][11], raw_data[i][12], raw_data[i][13],\n",
    "        raw_data[i][14]])\n",
    "    labels[i] = th.tensor([raw_data[i][3], raw_data[i][4], raw_data[i][5], raw_data[i][6]])\n",
    "\n",
    "# concatenate the features and labels\n",
    "\n",
    "# split the data into training, validation and test sets\n",
    "split_1 = int(0.7 * features.size(0))\n",
    "split_2 = int(0.85 * features.size(0))\n",
    "\n",
    "training_data = [features[:split_1], labels[:split_1]]\n",
    "validation_data = [features[split_1:split_2], labels[split_1:split_2]]\n",
    "test_data = [features[split_2:], labels[split_2:]]\n",
    "\n",
    "print (\"Training data size: \", training_data[0].size(0))\n",
    "print (\"Validation data size: \", validation_data[0].size(0))\n",
    "print (\"Test data size: \", test_data[0].size(0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception block\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernel=4, init_weights=True):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernel = num_kernel\n",
    "        kernels = []\n",
    "        for i in range(1, num_kernel + 1):\n",
    "            # kernels.append(nn.Conv2d(in_channels, out_channels // num_kernel, kernel_size=i * 2 + 1, padding=i))\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=i * 2 + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i in range(self.num_kernel):\n",
    "            outputs.append(self.kernels[i](x))\n",
    "        # outputs = th.stack(outputs, dim=1)\n",
    "        outputs = th.cat(outputs, dim=1).mean(dim=1)\n",
    "        return self.relu(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needc an embedding layer for the teams before the feedforward network\n",
    "\n",
    "class FootballPrediction(nn.Module):\n",
    "    def __init__(self, num_teams, num_features, num_labels, num_inception_blocks=1):\n",
    "        super(FootballPrediction, self).__init__()\n",
    "        self.team_embedding = nn.Embedding(num_teams, 10)\n",
    "        # inception block\n",
    "        self.inception_block = [InceptionBlock(num_features + 10, 64) for _ in range(num_inception_blocks)]\n",
    "\n",
    "\n",
    "        # would need a module that processes the sequential features\n",
    "        # self.feedforward = nn.Sequential(\n",
    "        #     nn.Linear(num_features + 10, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, num_labels)\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do we need to computer the berrar ratings here (??) or does the \n",
    "        # input already contain the berrar ratings (??)\n",
    "        # replace the team indexes with the embeddings\n",
    "        home_team = self.team_embedding(x[:, 0].long())\n",
    "        away_team = self.team_embedding(x[:, 1].long())\n",
    "        x = th.cat([x[:, 2:], home_team, away_team], dim=1)\n",
    "\n",
    "        # pass through the inception block\n",
    "        for block in self.inception_block:\n",
    "            x = block(x)\n",
    "\n",
    "\n",
    "        \n",
    "        return self.feedforward(x)\n",
    "    \n",
    "\n",
    "    def predict(self, x):\n",
    "        # have to decide on what is the shape for the input\n",
    "\n",
    "        return self.forward(x)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
